{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "278ab961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec3680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_tokens( text , stop_words ):\n",
    "    \"\"\" Convert text to array of words, remove stop words and punctuation, and stemming each word\n",
    "        \n",
    "    Args:\n",
    "        text ([string]) : [the text you want to convert]\n",
    "        stop_words ([string array]) : [words you want to remove]\n",
    "    \n",
    "    Return:\n",
    "        [string array] : [the words array of the converted text]\n",
    "        \n",
    "    Examples:\n",
    "        >>> from nltk.stem.porter import PorterStemmer\n",
    "        >>> from nltk.tokenize import RegexpTokenizer\n",
    "        >>> texts_to_tokens( \"the end of the string:\", [\"the\", \"of\"] )\n",
    "        array(['end', 'string'])\n",
    "    \"\"\"\n",
    "    \n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    porter = PorterStemmer()\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # remove punctuation    \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "        \n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    # steming words\n",
    "    stemmed = [porter.stem(word) for word in words]\n",
    "    # filter out stop words\n",
    "    words = [word for word in stemmed if not word in stop_words]\n",
    "        \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af8845c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def htmltotext(text):\n",
    "    \"\"\" Remove sapces from the text in html\n",
    "        \n",
    "        Args:\n",
    "            text ([string]) : [text]\n",
    "            \n",
    "        Return:\n",
    "            [string] : [the string without \"long spaces\"]\n",
    "            \n",
    "        Examples:\n",
    "            >>> htmltotext(\"     for   the    music       \")\n",
    "            'for\\nthe\\nmusic'\n",
    "    \"\"\"\n",
    "    \n",
    "    # break into lines and remove spaces leading and trailing for each\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    # break multi-headlines into a line each\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    # drop blank lines\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_actions( browser ):\n",
    "    import random\n",
    "    import time\n",
    "    \n",
    "    step = random.randint( 15,25 )\n",
    "    bias = 50\n",
    "    \n",
    "    for i in range (400,600, step):\n",
    "        \n",
    "        if i > 480+step:\n",
    "            browser.execute_script(\"window.moveTo({},{})\".format(step+2, step)) \n",
    "        \n",
    "        time.sleep(0.2)\n",
    "        browser.execute_script(\"window.scrollTo(0, {})\".format(bias+i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_url(url, browser, wait_time=None):\n",
    "    \"\"\" Send get query and return html\n",
    "        \n",
    "        Args:\n",
    "            url ([string]) : [the url for send get query]\n",
    "            browser ([selenium webdriver]) : [driver for send query]\n",
    "            wait_time (float, optional) : [the time after that close query]\n",
    "            \n",
    "        Return:\n",
    "            [string] : [html text]\n",
    "    \"\"\"\n",
    "    \n",
    "    if wait_time != None:\n",
    "        browser.set_page_load_timeout(wait_time)\n",
    "\n",
    "    try:\n",
    "        browser.get(url)\n",
    "        some_actions( browser )\n",
    "        cookies = browser.get_cookies()\n",
    "        # browser.delete_all_cookies()\n",
    "        for cookie in cookies:\n",
    "            browser.add_cookie(cookie)\n",
    "    except Exception as e:\n",
    "        # if problem with connect timeout just pass   \n",
    "        if \"timeout:\" not in str(e):\n",
    "            print( str(e) )\n",
    "          \n",
    "    html = browser.page_source\n",
    "    # replace \\\\ to cleaning html atributes correctly\n",
    "    html = html.replace( \"\\\\\", \"\" )\n",
    "    \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41cbf5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_new_articles( articles_url_name_new, articles_url_name ):\n",
    "    \"\"\" Chech if appear new articles\n",
    "    \n",
    "        Args:\n",
    "            articles_url_name_new ([string array]) : [the new array of urls]\n",
    "            articles_url_name ([string array]) : [the old array of urls]\n",
    "            \n",
    "        Return:\n",
    "            [string array] : [the array of new articles]\n",
    "            \n",
    "        Examples:\n",
    "            >>> check_new_articles(['a', 'b', 'c'], ['b', 'c'])\n",
    "            array(['a'])\n",
    "    \"\"\"\n",
    "      \n",
    "    old_urls = list( articles_url_name )\n",
    "    new_urls = list( articles_url_name_new )\n",
    "\n",
    "    # articles exist in new_urls but none in old    \n",
    "    new_articles_urls = list( set( new_urls ) - set(old_urls)   )\n",
    "\n",
    "    return new_articles_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d32582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_query( url, data ):\n",
    "    # send query to server    \n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    r = requests.post(url, json = json.dumps(data) , headers = {'Content-type': 'application/json', 'Accept': 'text/plain'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data( data, path ):\n",
    "    # save part of data\n",
    "    import pandas as pd\n",
    "    from time import gmtime, strftime\n",
    "    \n",
    "    data[:150].to_csv( path+\"-\"+strftime(\"%Y-%m-%d-%H-%M\", gmtime()) + \".csv\" , index=False )\n",
    "    return data[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3448cca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48ebbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
